# UGC Video Generation Platform - Technical Setup Guide

This document provides a comprehensive guide to set up the UGC Video Generation Platform with serverless architecture.

## Architecture Overview

![Architecture Diagram](https://i.imgur.com/example.png)

This platform uses a serverless architecture with the following components:

- **Frontend**: React application deployed on Vercel
- **Database**: Supabase (PostgreSQL + Authentication + Storage)
- **Video Processing**: AWS Lambda + FFmpeg
- **Video Storage**: AWS S3 bucket

The workflow is fully event-driven:
1. Frontend sends video generation requests to Supabase
2. Lambda function processes the video and stores it in S3
3. Lambda updates Supabase with the S3 video URL
4. Frontend displays the processed video in real-time

## Prerequisites

- [Node.js](https://nodejs.org/) (v18 or higher)
- [AWS Account](https://aws.amazon.com/)
- [Supabase Account](https://supabase.com/)
- [Vercel Account](https://vercel.com/)
- Git and GitHub account

## Setup Instructions

### Step 1: Supabase Setup

1. **Create a new Supabase project**
    - Navigate to [Supabase](https://supabase.com/)
    - Create a new project with a descriptive name
    - Save your project URL and API keys for later use

2. **Initialize database schema**
    - Navigate to the SQL Editor in Supabase
    - Run the following SQL to set up your database schema:

```sql
    -- Enum Types
    create type plan as enum ('free', 'pro', 'ultra');
    create type template_type as enum ('aiavatar', 'game', 'usergenerated');
    create type text_alignment as enum ('top', 'center', 'bottom');
    create type video_alignment as enum ('side', 'top', 'serial');
    create type video_type as enum ('aiugc', 'meme');
    
    -- Create Tables
-- PROFILES TABLE
    create table public.profiles (
      id uuid not null,
      username text null,
      avatar_url text null,
      created_at timestamp with time zone not null default now(),
      updated_at timestamp with time zone not null default now(),
      plan public.plan not null default 'free'::plan,
      credits integer not null default 3,
      email text null,
      constraint profiles_pkey primary key (id),
      constraint profiles_id_fkey foreign KEY (id) references auth.users (id) on delete CASCADE
    );
    
    -- Set up Row Level Security (RLS)
    alter table public.profiles enable row level security;
    
    create policy "Users can update their own profile" on public.profiles
       for update to public using (auth.uid() = id);
    create policy "Users can view their own profile" on public.profiles
       for select to public using (auth.uid() = id);
    create policy "Users can delete their own profile" on public.profiles
      for delete to public using (auth.uid() = id);
    
    -- DEMO TABLE
    create table public.demo (
      id bigint generated by default as identity not null,
      created_at timestamp with time zone not null default now(),
      demo_link text not null,
      user_id uuid not null,
      constraint demo_pkey primary key (id),
      constraint demo_user_id_fkey foreign KEY (user_id) references profiles (id) on delete CASCADE
    );
    
    -- Set up Row Level Security (RLS)
    alter table public.demo enable row level security;
    
    create policy "Allow users to insert their own demos" on public.demo
       for insert to authenticated with check (user_id = auth.uid());
    create policy "Users can update their own demos" on public.demo
       for update to public using (auth.uid() = user_id);
    create policy "Allow users to view their own demos" on public.demo
       for select to authenticated using (user_id = auth.uid());
    create policy "Allow users to delete their own demos" on public.demo
      for delete to authenticated using (user_id = auth.uid());
    
    -- GENERATED VIDEOS TABLE
    create table public.generated_videos (
      id uuid not null default gen_random_uuid (),
      created_at timestamp with time zone not null default now(),
      text_alignment public.text_alignment not null,
      video_alignment public.video_alignment null,
      video_type public.video_type not null,
      user_id uuid not null,
      demo_id bigint null,
      sound_id bigint null,
      template_id bigint null,
      remotion jsonb null,
      remotion_video text null,
      status text not null default 'pending'::text,
      error text null,
      caption text null,
      completed_at timestamp with time zone null,
      constraint generated_videos_pkey primary key (id),
      constraint generated_videos_user_id_fkey foreign KEY (user_id) references profiles (id) on delete CASCADE
    );
    
    -- Set up Row Level Security (RLS)
    alter table public.generated_videos enable row level security;
    
    create policy "Users can insert their own generated videos" on public.generated_videos
       for insert to public with check (user_id = auth.uid());
    create policy "Users can update their own generated videos" on public.generated_videos
       for update to public using (auth.uid() = user_id);
    create policy "Users can view their own generated videos" on public.generated_videos
       for select to public using (user_id = auth.uid());
    create policy "Users can delete their own generated videos" on public.generated_videos
      for delete to public using (user_id = auth.uid());
    
    -- Enable Realtime for public.generated_videos
    alter publication supabase_realtime add table public.generated_videos;
    
    -- Setup Auth Hooks
    CREATE OR REPLACE FUNCTION public.handle_new_user()
    RETURNS trigger
    LANGUAGE plpgsql
    SECURITY DEFINER
    AS $$
    BEGIN
      INSERT INTO public.profiles (id, email)
      VALUES (new.id, new.email);
      RETURN new;
    END;
    $$;
    
    -- Create a trigger to call the function when a new user is created
    CREATE TRIGGER on_auth_user_created
      AFTER INSERT ON auth.users
      FOR EACH ROW EXECUTE FUNCTION public.handle_new_user();
```

3. **Create storage buckets**
    - Go to the Storage section in Supabase
    - Create the following buckets:
        - `sound` (public)
        - `template` (public)
        - `generated-videos` (public)
        - `user-templates` (public)

4. **Configure authentication**
    - Navigate to Authentication > Providers
    - Enable Google authentication
    - Add your application's URL to the callback URL list

### Step 2: AWS Setup

1. **Create S3 bucket**
    - Navigate to S3 in the AWS Console
    - Create a new bucket named `ugclive-videos-us` (or your preferred name)
    - Create three folders inside the bucket:
        - `videos/` (for storing final videos)
        - `temp/` (for temporary processing files)
        - `assets/` (optional, for any static assets)
    - Configure CORS to allow access from your frontend

2. **Create Lambda function**
    - Navigate to Lambda in the AWS Console
    - Create a new function:
        - Name: `ugclive-video-processor`
        - Runtime: Node.js 18.x
        - Memory: 3000 MB
        - Timeout: 15 minutes
    - Add custom FFmpeg layer (create or use an existing layer with FFmpeg binaries)
    - Set environment variables:
        ```
        SUPABASE_URL=your-supabase-url
        SUPABASE_KEY=your-supabase-service-key
        S3_BUCKET=ugclive-videos-us
        ```

3. **Create API Gateway**
    - Create an HTTP API (not REST API)
    - Add route: `/generate-video` (ANY method)
    - Connect to your Lambda function
    - Deploy the API to a stage
    - Note the API endpoint URL: `https://your-api-id.execute-api.region.amazonaws.com/generate-video`

4. **Set up IAM permissions**
    - Ensure the Lambda has the following permissions:
        - S3 full access to your bucket
        - CloudWatch logging permissions
        - MediaConvert permissions (if needed)
    - Sample policy:
    ```json
    {
        "Version": "2012-10-17",
        "Statement": [
            {
                "Effect": "Allow",
                "Action": [
                    "s3:PutObject",
                    "s3:GetObject",
                    "s3:DeleteObject",
                    "logs:CreateLogGroup",
                    "logs:CreateLogStream",
                    "logs:PutLogEvents"
                ],
                "Resource": [
                    "arn:aws:s3:::ugclive-videos-us/*",
                    "arn:aws:logs:*:*:*"
                ]
            }
        ]
    }
    ```

5. **Deploy Lambda code**
    - Upload the following code to your Lambda function:

```javascript
const { createClient } = require('@supabase/supabase-js');
const AWS = require('aws-sdk');
const ffmpeg = require('fluent-ffmpeg');
const fs = require('fs');
const path = require('path');
const https = require('https');
const http = require('http');

// Initialize S3
const s3 = new AWS.S3();

// Initialize Supabase
const supabaseUrl = process.env.SUPABASE_URL;
const supabaseKey = process.env.SUPABASE_KEY;
const supabase = createClient(supabaseUrl, supabaseKey);

// Find FFmpeg in various possible locations
const possibleFfmpegPaths = [
  '/opt/ffmpeg/ffmpeg',
  '/opt/bin/ffmpeg',
  '/opt/ffmpeg',
  '/var/task/ffmpeg',
  '/opt/usr/bin/ffmpeg',
  '/var/runtime/ffmpeg'
];

let ffmpegPath = null;
for (const path of possibleFfmpegPaths) {
  try {
    if (fs.existsSync(path)) {
      ffmpegPath = path;
      console.log(`Found FFmpeg at: ${path}`);
      break;
    }
  } catch (e) {
    console.log(`Error checking path ${path}:`, e.message);
  }
}

if (!ffmpegPath) {
  console.error('FFmpeg not found in any expected location');
}

// Find FFprobe in various possible locations
const possibleFfprobePaths = [
  '/opt/ffmpeg/ffprobe',
  '/opt/bin/ffprobe',
  '/opt/ffprobe',
  '/var/task/ffprobe',
  '/opt/usr/bin/ffprobe',
  '/var/runtime/ffprobe'
];

let ffprobePath = null;
for (const path of possibleFfprobePaths) {
  try {
    if (fs.existsSync(path)) {
      ffprobePath = path;
      console.log(`Found FFprobe at: ${path}`);
      break;
    }
  } catch (e) {
    console.log(`Error checking path ${path}:`, e.message);
  }
}

// Configure FFmpeg paths
if (ffmpegPath) {
  try {
    ffmpeg.setFfmpegPath(ffmpegPath);
    console.log(`Set FFmpeg path to: ${ffmpegPath}`);
  } catch (e) {
    console.error('Error setting FFmpeg path:', e.message);
  }
}

if (ffprobePath) {
  try {
    ffmpeg.setFfprobePath(ffprobePath);
    console.log(`Set FFprobe path to: ${ffprobePath}`);
  } catch (e) {
    console.error('Error setting FFprobe path:', e.message);
  }
}

// Helper function to download a file
async function downloadFile(url, outputPath) {
  console.log(`Downloading from: ${url} to: ${outputPath}`);
  
  return new Promise((resolve, reject) => {
    const protocol = url.startsWith('https') ? https : http;
    const file = fs.createWriteStream(outputPath);
    
    protocol.get(url, (response) => {
      console.log(`Download response status: ${response.statusCode}`);
      
      if (response.statusCode !== 200) {
        reject(new Error(`Failed to download file: ${response.statusCode}`));
        return;
      }
      
      response.pipe(file);
      
      file.on('finish', () => {
        file.close();
        console.log(`Download complete for: ${outputPath}`);
        resolve(outputPath);
      });
      
      file.on('error', (err) => {
        console.error(`Error writing to file: ${err.message}`);
        file.close();
        fs.unlink(outputPath, () => {});
        reject(err);
      });
    }).on('error', (err) => {
      console.error(`Error downloading file: ${err.message}`);
      fs.unlink(outputPath, () => {});
      reject(err);
    });
  });
}

// Helper function to ensure compatible codec
async function ensureCompatibleCodec(videoUrl, id) {
  if (!videoUrl) {
    console.error('No video URL provided');
    return null;
  }
  
  console.log(`Processing video: ${videoUrl}`);
  
  try {
    // Download the source video to /tmp
    const sourcePath = `/tmp/source-${id}.mp4`;
    await downloadFile(videoUrl, sourcePath);
    
    console.log(`Source video downloaded to: ${sourcePath}`);
    console.log(`File exists: ${fs.existsSync(sourcePath)}`);
    console.log(`File size: ${fs.statSync(sourcePath).size} bytes`);
    
    // Output path for transcoded video
    const outputPath = `/tmp/h264-${id}.mp4`;
    
    // Check if FFmpeg is available
    if (!ffmpegPath) {
      console.error('FFmpeg not found, returning source file');
      return sourcePath; // Just return the source if FFmpeg isn't available
    }
    
    // Transcode to H.264 (with more logging)
    return new Promise((resolve, reject) => {
      console.log(`Starting FFmpeg transcoding with path: ${ffmpegPath}`);
      
      ffmpeg(sourcePath)
        .outputOptions([
          '-c:v libx264', 
          '-preset fast',
          '-crf 23',
          '-c:a aac'
        ])
        .output(outputPath)
        .on('start', (commandLine) => {
          console.log('FFmpeg command:', commandLine);
        })
        .on('progress', (progress) => {
          console.log(`Transcoding progress: ${JSON.stringify(progress)}`);
        })
        .on('end', () => {
          console.log('Transcoding completed successfully');
          if (fs.existsSync(outputPath)) {
            console.log(`Output file exists: ${fs.existsSync(outputPath)}`);
            console.log(`Output file size: ${fs.statSync(outputPath).size} bytes`);
            // Don't delete source yet for debugging
            resolve(outputPath);
          } else {
            console.error(`Output file does not exist at: ${outputPath}`);
            resolve(sourcePath); // Use source as fallback
          }
        })
        .on('error', (err) => {
          console.error('Transcoding error:', err);
          console.log('Returning source file due to transcoding error');
          resolve(sourcePath); // Return source file on error as fallback
        })
        .run();
    });
  } catch (error) {
    console.error('Error in video processing:', error);
    throw error;
  }
}

// List files in /tmp for debugging
function listTempFiles() {
  try {
    console.log('Listing files in /tmp:');
    const files = fs.readdirSync('/tmp');
    files.forEach(file => {
      try {
        const stats = fs.statSync(`/tmp/${file}`);
        console.log(`- ${file}: ${stats.size} bytes`);
      } catch (e) {
        console.log(`- ${file}: [Error getting stats: ${e.message}]`);
      }
    });
  } catch (error) {
    console.error('Error listing /tmp files:', error);
  }
}

// Main Lambda handler
exports.handler = async (event) => {
  let id = null;
  let processedVideoPath = null;
  
  try {
    console.log('Lambda function started');
    console.log('Event:', JSON.stringify(event));
    
    // List environment variables for debugging
    console.log('Environment variables:');
    console.log(`- SUPABASE_URL: ${supabaseUrl ? '✓ Set' : '✗ Missing'}`);
    console.log(`- SUPABASE_KEY: ${supabaseKey ? '✓ Set' : '✗ Missing'}`);
    console.log(`- S3_BUCKET: ${process.env.S3_BUCKET || 'Not set, using default: ugclive-videos-us'}`);
    
    // Parse the request body
    const body = JSON.parse(event.body || '{}');
    id = body.id;
    const data = body.data;
    
    console.log('Parsed request body:', JSON.stringify(body));
    
    // Validate required fields
    if (!id || !data) {
      throw new Error("Missing required parameters: id and data");
    }
    
    console.log(`Processing video generation for ID: ${id}`);
    
    // Update status in Supabase
    try {
      const { error } = await supabase
        .from('generated_videos')
        .update({ status: 'processing' })
        .eq('id', id);
        
      if (error) {
        console.error('Error updating status in Supabase:', error);
      } else {
        console.log('Status updated to "processing" in Supabase');
      }
    } catch (e) {
      console.error('Exception updating status in Supabase:', e);
    }

    // Extract properties from data
    const remotionData = data.remotion || {};
    const videoSource = remotionData.template;
    
    if (!videoSource) {
      throw new Error("No video source provided");
    }
    
    // Process video for compatibility
    console.log("Processing video for compatibility...");
    processedVideoPath = await ensureCompatibleCodec(videoSource, id);
    
    if (!processedVideoPath) {
      throw new Error("Failed to process video");
    }
    
    // List files in /tmp for debugging
    listTempFiles();
    
    // Upload to S3
    console.log("Uploading to S3...");
    
    if (!fs.existsSync(processedVideoPath)) {
      throw new Error(`Processed video file not found at: ${processedVideoPath}`);
    }
    
    const fileSize = fs.statSync(processedVideoPath).size;
    console.log(`File size before upload: ${fileSize} bytes`);
    
    if (fileSize === 0) {
      throw new Error('Processed video file is empty');
    }
    
    const fileStream = fs.createReadStream(processedVideoPath);
    const s3Bucket = process.env.S3_BUCKET || 'ugclive-videos-us';
    
    console.log(`Uploading to S3 bucket: ${s3Bucket}, key: videos/${id}.mp4`);
    
    const s3Response = await s3.upload({
      Bucket: s3Bucket,
      Key: `videos/${id}.mp4`,
      Body: fileStream,
      ContentType: 'video/mp4'
    }).promise();
    
    console.log('S3 upload successful:', s3Response);
    
    // Update Supabase with S3 URL
    console.log("Updating Supabase with video URL...");
    const { error: updateError } = await supabase
      .from('generated_videos')
      .update({ 
        status: 'completed',
        remotion_video: s3Response.Location,
        completed_at: new Date().toISOString()
      })
      .eq('id', id);
      
    if (updateError) {
      console.error('Error updating completion status in Supabase:', updateError);
    } else {
      console.log('Status updated to "completed" in Supabase');
    }
    
    // Clean up temp files
    console.log('Cleaning up temporary files');
    try {
      if (fs.existsSync(processedVideoPath)) {
        fs.unlinkSync(processedVideoPath);
        console.log(`Deleted: ${processedVideoPath}`);
      }
    } catch (e) {
      console.error(`Error deleting temporary files: ${e.message}`);
    }
    
    console.log("Video processing completed successfully");
    
    return {
      statusCode: 200,
      headers: {
        'Access-Control-Allow-Origin': '*',
        'Access-Control-Allow-Credentials': true,
      },
      body: JSON.stringify({
        success: true,
        id: id,
        url: s3Response.Location
      })
    };
  } catch (error) {
    console.error('Error:', error);
    
    // Update error status in Supabase
    if (id) {
      try {
        const { error: updateError } = await supabase
          .from('generated_videos')
          .update({ 
            status: 'error',
            error: error.message
          })
          .eq('id', id);
          
        if (updateError) {
          console.error('Error updating error status in Supabase:', updateError);
        } else {
          console.log('Status updated to "error" in Supabase');
        }
      } catch (dbError) {
        console.error('Failed to update error status in database:', dbError);
      }
    }
    
    // Clean up temp files on error
    try {
      if (processedVideoPath && fs.existsSync(processedVideoPath)) {
        fs.unlinkSync(processedVideoPath);
      }
    } catch (e) {
      console.error(`Error cleaning up on failure: ${e.message}`);
    }
    
    return {
      statusCode: 500,
      headers: {
        'Access-Control-Allow-Origin': '*',
        'Access-Control-Allow-Credentials': true,
      },
      body: JSON.stringify({
        success: false,
        error: error.message
      })
    };
  }
};
```

### Step 3: Frontend Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/ugclive.git
   cd ugclive/frontend
   ```

2. **Configure environment variables**
   Create a `.env` file with the following content:
   ```
   # Supabase Configuration
   VITE_SUPABASE_URL=your-supabase-url
   VITE_SUPABASE_ANON_KEY=your-supabase-anon-key

   # API Configuration
   VITE_API_URL=https://your-api-id.execute-api.region.amazonaws.com/generate-video

   # App Configuration
   VITE_APP_NAME=UGClive
   VITE_APP_URL=https://your-app-domain.com

   # S3 Configuration
   S3_BUCKET=ugclive-videos-us
   ```

3. **Install dependencies**
   ```bash
   npm install
   ```

4. **Run locally for testing**
   ```bash
   npm run dev
   ```

5. **Deploy to Vercel**
   - Connect your GitHub repository to Vercel
   - Configure the environment variables in Vercel settings
   - Deploy the frontend

## End-to-End Workflow

### Video Generation Process

1. **Frontend to Supabase**:
   - User creates a video using the ContentGenerator component
   - Frontend saves a record to the `generated_videos` table with `status: 'pending'`
   - Record includes template, caption, and layout settings

2. **Lambda Processing**:
   - Lambda function processes the Supabase record
   - Downloads source video
   - Transcodes using FFmpeg with compatible codecs
   - Uploads processed video to S3 bucket

3. **S3 Storage**:
   - Processed video is stored in the `videos/` folder in S3
   - S3 URL format: `https://ugclive-videos-us.s3.region.amazonaws.com/videos/{id}.mp4`

4. **Supabase Update**:
   - Lambda updates the Supabase record with:
     - `status: 'completed'`
     - `remotion_video: S3_URL`
     - `completed_at: timestamp`

5. **Frontend Display**:
   - Dashboard automatically refreshes via Supabase Realtime
   - VideoCard component displays the processed video
   - Video status is reflected in the UI (pending, processing, completed, error)

### Component Interactions

- **ContentGenerator**: Creates video generation requests
- **VideoGrid**: Displays user's videos
- **VideoCard**: Shows playable videos with status indicators
- **useVideos hook**: Provides real-time updates via Supabase subscriptions

## Troubleshooting

### Lambda Issues
- Check CloudWatch logs for detailed error messages
- Verify FFmpeg paths and permissions
- Ensure S3 bucket policies are correctly set
- Test direct POST requests to API Gateway endpoint

### Frontend Issues
- Check browser console for JavaScript errors
- Verify Supabase connection and authentication
- Ensure API endpoint is correctly configured in environment variables

### Supabase Issues
- Verify Realtime feature is enabled for the `generated_videos` table
- Check Row Level Security policies
- Monitor database for orphaned or inconsistent records

## Maintenance

- Regularly monitor AWS CloudWatch for Lambda errors
- Check S3 storage usage and implement lifecycle policies if needed
- Monitor Supabase database size and performance
- Update FFmpeg layer when new versions are available

## Security Considerations

- Secure your API Gateway with proper authentication
- Review Supabase RLS policies regularly
- Consider implementing rate limiting
- Encrypt sensitive environment variables
- Configure CORS policies to restrict access

---

This setup provides a serverless, scalable architecture for video generation with minimal operational overhead. The Lambda function handles all the processing work, S3 stores the results, and Supabase manages the database and real-time updates.
